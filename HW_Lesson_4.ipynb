{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPNPohV/00+PY4aEUyxBnKU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["\n","    Обучить модель семантической сегментации (человек-vs-фон) на подмножестве датасета MS COCO\n","    Библиотеки: [Python, Tensorflow]\n","\n"],"metadata":{"id":"m4WgCxq_K4DH"}},{"cell_type":"code","source":[],"metadata":{"id":"3Q0OKAGMvEWO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-mYY42BSBOi1"},"source":["# Семантическая Сегментация. Часть 3."]},{"cell_type":"markdown","metadata":{"id":"ty18tSuABT9X"},"source":["## Переключение версии TensorFlow"]},{"cell_type":"code","metadata":{"id":"fS42SrF5Tm4H"},"source":["%tensorflow_version 2.x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zvoeKMnP0V7j"},"source":["import os\n","import skimage.io as io\n","import numpy as np\n","\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-rSwyWz-BU9t"},"source":["## Загрузка датасета COCO и COCO API"]},{"cell_type":"code","metadata":{"id":"H306Fzq_0Mzi"},"source":["if 1:\n","    !mkdir -p data\n","\n","    # !cd data && wget http://images.cocodataset.org/zips/train2017.zip \n","    # !cd data && wget http://images.cocodataset.org/zips/val2017.zip \n","    !cd data && wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip \n","\n","    # !cd data && unzip -q train2017.zip\n","    # !cd data && unzip -q val2017.zip\n","    !cd data && unzip -q annotations_trainval2017.zip\n","\n","    !cd data && git clone https://github.com/cocodataset/cocoapi\n","    !cd data/cocoapi/PythonAPI && make"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y0xB9xnQBbV2"},"source":["## Подготовка COCO API"]},{"cell_type":"code","metadata":{"id":"FLYZPXQg1m94"},"source":["COCO_ROOT = './data/'\n","import sys\n","sys.path.insert(0, os.path.join(COCO_ROOT, 'cocoapi/PythonAPI'))\n","from pycocotools.coco import COCO"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0yLcNgZOBgQ0"},"source":["## Универсальный класс Dataset для сегментации"]},{"cell_type":"code","metadata":{"id":"bZhpoFlh1rmE"},"source":["class Dataset():\n","\n","    def crop_images(self, img, inp_size, random_crop=False):\n","        shape = tf.shape(img)\n","        pad = (\n","            [0, tf.maximum(inp_size - shape[0], 0)],\n","            [0, tf.maximum(inp_size - shape[1], 0)],\n","            [0, 0],\n","        )\n","        img = tf.pad(img, pad)\n","\n","        if random_crop:\n","            img = tf.image.random_crop(img, (inp_size, inp_size, shape[2]))\n","        else: # central crop\n","            shape = tf.shape(img)\n","            ho = (shape[0] - inp_size) // 2\n","            wo = (shape[1] - inp_size) // 2\n","            img = img[ho:ho+inp_size, wo:wo+inp_size, :]\n","\n","        return img\n","\n","    def train_dataset(self, batch_size, epochs, inp_size):\n","\n","        def item_to_images(item):\n","            random_crop = True\n","            img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n","            img_combined = self.crop_images(img_combined, inp_size, random_crop)\n","\n","            img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255.)\n","            mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n","            return img, mask_class\n","\n","        dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n","        dataset = dataset.shuffle(buffer_size=len(self.img_list))\n","        dataset = dataset.map(item_to_images)\n","        dataset = dataset.repeat(epochs)\n","        dataset = dataset.batch(batch_size, drop_remainder=True)\n","\n","        return dataset\n","\n","    def val_dataset(self, batch_size, inp_size):\n","\n","        def item_to_images(item):\n","            random_crop = False\n","            img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n","            img_combined = self.crop_images(img_combined, inp_size, random_crop)\n","\n","            img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255.)\n","            mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n","            return img, mask_class\n","\n","        dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n","        dataset = dataset.map(item_to_images)\n","        dataset = dataset.batch(batch_size, drop_remainder=True)\n","\n","        return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZPXZGUhHBn3Q"},"source":["## Класс для сегментационного датасета COCO\n","Класс наследутся от универсльного `Dataset` и реализует кастомную функцию чтения данных."]},{"cell_type":"code","metadata":{"id":"MjYwt86l1xMt"},"source":["class COCO_Dataset(Dataset):\n","\n","    def __init__(self, sublist):\n","        ann_file_fpath = os.path.join(COCO_ROOT, 'annotations', 'instances_'+sublist+'2017.json')\n","        self.coco = COCO(ann_file_fpath)\n","        self.cat_ids = self.coco.getCatIds(catNms=['person'])\n","        self.img_list = self.coco.getImgIds(catIds=self.cat_ids)\n","\n","    def read_images(self, img_id):\n","        img_id = int(img_id.numpy())\n","        img_data = self.coco.loadImgs(img_id)[0]\n","        img_fname = '/'.join(img_data['coco_url'].split('/')[-2:])\n","\n","        img = io.imread(os.path.join(COCO_ROOT, img_fname))\n","        if len(img.shape) == 2:\n","            img = np.tile(img[..., None], (1, 1, 3))\n","\n","        ann_ids = self.coco.getAnnIds(imgIds=img_data['id'], catIds=self.cat_ids, iscrowd=None)\n","        anns = self.coco.loadAnns(ann_ids)\n","        mask_class = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n","        for i in range(len(anns)):\n","            mask_class += self.coco.annToMask(anns[i])\n","        mask_class = (mask_class > 0).astype(np.uint8)\n","\n","        img_combined = np.concatenate([img, mask_class[..., None]], axis=2)\n","\n","        return img_combined"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-08-25T13:34:10.206966Z","start_time":"2021-08-25T13:33:47.026946Z"},"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"5c01c03f","executionInfo":{"status":"ok","timestamp":1662475758069,"user_tz":-180,"elapsed":18958,"user":{"displayName":"Эс Ен","userId":"08339065881474185137"}},"outputId":"78549256-2bac-4e85-a1e5-4b12b13a6459"},"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=16.58s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=0.49s)\n","creating index...\n","index created!\n"]}],"source":["COCO_dataset_train = COCO_Dataset('train')\n","COCO_dataset_val = COCO_Dataset('val')"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-08-25T13:34:10.222946Z","start_time":"2021-08-25T13:34:10.207949Z"},"id":"a748b89a"},"outputs":[],"source":["INP_SIZE = 256\n","NUM_EPOCHS_REPEAT = 1\n","BATCH_SIZE = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-08-25T13:34:11.509959Z","start_time":"2021-08-25T13:34:10.224947Z"},"id":"8ad9aacc"},"outputs":[],"source":["train_ds = COCO_dataset_train.train_dataset(BATCH_SIZE, NUM_EPOCHS_REPEAT, INP_SIZE)\n","val_ds = COCO_dataset_val.val_dataset(BATCH_SIZE, INP_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"d98db383"},"source":["*******************"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-08-25T13:34:11.921967Z","start_time":"2021-08-25T13:34:11.510946Z"},"id":"4a1978c2"},"outputs":[],"source":["input_layers = tf.keras.Sequential([\n","    tf.keras.layers.InputLayer(input_shape=(INP_SIZE, INP_SIZE, 3)),\n","    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n","    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')])"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-08-25T13:34:11.953948Z","start_time":"2021-08-25T13:34:11.922947Z"},"id":"4a340e0d"},"outputs":[],"source":["class ASPPBlock(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = tf.keras.layers.Conv2D(256, (1, 1), padding='same', activation='relu')\n","        self.conv2 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=6, padding='same', activation='relu')\n","        self.conv3 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=12, padding='same', activation='relu')\n","        self.conv4 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=18, padding='same', activation='relu')\n","        self.conv5 = tf.keras.layers.Conv2D(256, (1, 1), padding='same', activation='relu')\n","\n","    def call(self, inp, is_training=False):\n","        out1 = self.conv1(inp)\n","        out2 = self.conv2(inp)\n","        out3 = self.conv3(inp)\n","        out4 = self.conv4(inp)\n","        out = tf.concat([out1, out2, out3, out4], axis=3)\n","        out = self.conv5(out)\n","        return out\n","    \n","class ASPPNet(tf.keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv3 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n","        self.conv4 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n","        self.conv5 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n","        self.conv6 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n","        self.conv7 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n","        self.conv8 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n","        self.conv9 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n","        self.conv10 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n","        self.conv11 = tf.keras.layers.Conv2D(48, (1, 1), padding='same', activation='relu')\n","        self.conv12 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n","        self.conv13 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n","        self.conv14 = tf.keras.layers.Conv2D(1, (1, 1), padding='same', activation=None)\n","        self.maxpool = tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')\n","        self.aspp = ASPPBlock()\n","\n","    def call(self, x):\n","\n","        out = input_layers(x)\n","        out = self.maxpool(out)\n","        out = self.conv3(out)\n","        out = self.conv4(out)\n","        out = self.maxpool(out)\n","        out = self.conv5(out)\n","        out = self.conv6(out)\n","        out_enc_mid = out\n","        out = self.maxpool(out)\n","        out = self.conv7(out)\n","        out = self.conv8(out)\n","        out = self.maxpool(out)\n","        out = self.conv9(out)\n","        out = self.conv10(out)\n","        out = self.aspp(out)\n","        out = tf.image.resize(out, tf.shape(out_enc_mid)[1:3], tf.image.ResizeMethod.BILINEAR)\n","        out_enc_mid = self.conv11(out_enc_mid)\n","        out = tf.concat([out, out_enc_mid], axis=3)\n","        out = self.conv12(out)\n","        out = self.conv13(out)\n","        out = self.conv14(out)\n","        out = tf.image.resize(out, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)\n","        out = tf.nn.sigmoid(out)\n","        \n","        return out"]},{"cell_type":"markdown","metadata":{"id":"fb087f43"},"source":["******************"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-08-25T13:34:11.969960Z","start_time":"2021-08-25T13:34:11.954947Z"},"id":"546f3ef5"},"outputs":[],"source":["NUM_EPOCHS = 1\n","loss = tf.keras.losses.BinaryCrossentropy()\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-08-25T13:34:12.016966Z","start_time":"2021-08-25T13:34:11.970946Z"},"id":"9d2cb5a3"},"outputs":[],"source":["model = ASPPNet()\n","model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-08-25T20:29:47.902988Z","start_time":"2021-08-25T13:34:12.017947Z"},"id":"87b4f339","outputId":"958bbb5e-2897-4c30-e8a1-afad3c9e5f1e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662478360686,"user_tz":-180,"elapsed":2303251,"user":{"displayName":"Эс Ен","userId":"08339065881474185137"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2003/2003 [==============================] - 2268s 1s/step - loss: 0.3843 - accuracy: 0.8215 - val_loss: 0.3474 - val_accuracy: 0.8385\n"]}],"source":["history = model.fit(train_ds,\n","                    epochs=NUM_EPOCHS,\n","                    validation_data=val_ds,\n","                    callbacks=[early_stopping])"]}]}