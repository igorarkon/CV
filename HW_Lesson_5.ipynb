{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import glob\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import colab_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "  \n",
    "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "  image = Image.open(BytesIO(img_data)) \n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def plot_detections(image_np,\n",
    "                    boxes,\n",
    "                    classes,\n",
    "                    scores,\n",
    "                    category_index,\n",
    "                    figsize=(12, 16),\n",
    "                    image_name=None):\n",
    "\n",
    "  image_np_with_annotations = image_np.copy()\n",
    "  \n",
    "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np_with_annotations,\n",
    "      boxes,\n",
    "      classes,\n",
    "      scores,\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      min_score_thresh=0.8)\n",
    "  if image_name:\n",
    "    plt.imsave(image_name, image_np_with_annotations) \n",
    "  else:\n",
    "    plt.imshow(image_np_with_annotations) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_dir = 'models/research/object_detection/test_images/ducky/train/'\n",
    "train_images_np = [] \n",
    "for i in range(1, 6):\n",
    "  image_path = os.path.join(train_image_dir, 'robertducky' + str(i) + '.jpg')\n",
    "  train_images_np.append(load_image_into_numpy_array(image_path))\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "plt.rcParams['xtick.labelsize'] = False\n",
    "plt.rcParams['ytick.labelsize'] = False\n",
    "plt.rcParams['xtick.top'] = False\n",
    "plt.rcParams['xtick.bottom'] = False\n",
    "plt.rcParams['ytick.left'] = False\n",
    "plt.rcParams['ytick.right'] = False\n",
    "plt.rcParams['figure.figsize'] = [14, 7]\n",
    "\n",
    "for idx, train_image_np in enumerate(train_images_np):\n",
    "  plt.subplot(2, 3, idx+1)\n",
    "  plt.imshow(train_image_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxes = []\n",
    "colab_utils.annotate(train_images_np, box_storage_pointer=gt_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_boxes = [\n",
    "            np.array([[0.436, 0.591, 0.629, 0.712]], dtype=np.float32),\n",
    "            np.array([[0.539, 0.583, 0.73, 0.71]], dtype=np.float32),\n",
    "            np.array([[0.464, 0.414, 0.626, 0.548]], dtype=np.float32),\n",
    "            np.array([[0.313, 0.308, 0.648, 0.526]], dtype=np.float32),\n",
    "            np.array([[0.256, 0.444, 0.484, 0.629]], dtype=np.float32)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_class_id = 1\n",
    "num_classes = 1\n",
    "\n",
    "category_index = {duck_class_id: {'id': duck_class_id, 'name': 'rubber_ducky'}}\n",
    "\n",
    "\n",
    "label_id_offset = 1\n",
    "train_image_tensors = []\n",
    "gt_classes_one_hot_tensors = []\n",
    "gt_box_tensors = []\n",
    "for (train_image_np, gt_box_np) in zip(train_images_np, gt_boxes):\n",
    "  train_image_tensors.append(tf.expand_dims(tf.convert_to_tensor(train_image_np, dtype=tf.float32), axis=0))\n",
    "  gt_box_tensors.append(tf.convert_to_tensor(gt_box_np, dtype=tf.float32))\n",
    "  zero_indexed_groundtruth_classes = tf.convert_to_tensor(np.ones(shape=[gt_box_np.shape[0]], dtype=np.int32) - label_id_offset)\n",
    "  gt_classes_one_hot_tensors.append(tf.one_hot(zero_indexed_groundtruth_classes, num_classes))\n",
    "print('Done prepping data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_scores = np.array([1.0], dtype=np.float32)  # бокс для score 100%\n",
    "\n",
    "plt.figure(figsize=(30, 15))\n",
    "for idx in range(5):\n",
    "  plt.subplot(2, 3, idx+1)\n",
    "  plot_detections(\n",
    "      train_images_np[idx],\n",
    "      gt_boxes[idx],\n",
    "      np.ones(shape=[gt_boxes[idx].shape[0]], dtype=np.int32),\n",
    "      dummy_scores, category_index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
    "!tar -xf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
    "!mv ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint models/research/object_detection/test_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "print('Building model and restoring weights for fine-tuning...', flush=True)\n",
    "num_classes = 1\n",
    "pipeline_config = 'models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config'\n",
    "checkpoint_path = 'models/research/object_detection/test_data/checkpoint/ckpt-0'\n",
    "\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
    "model_config = configs['model']\n",
    "model_config.ssd.num_classes = num_classes\n",
    "model_config.ssd.freeze_batchnorm = True\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=True)\n",
    "\n",
    "\n",
    "fake_box_predictor = tf.compat.v2.train.Checkpoint(\n",
    "    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,\n",
    "    _box_prediction_head=detection_model._box_predictor._box_prediction_head,\n",
    "    )\n",
    "\n",
    "fake_model = tf.compat.v2.train.Checkpoint(\n",
    "          _feature_extractor=detection_model._feature_extractor,\n",
    "          _box_predictor=fake_box_predictor)\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=fake_model)\n",
    "ckpt.restore(checkpoint_path).expect_partial()\n",
    "\n",
    "image, shapes = detection_model.preprocess(tf.zeros([1, 640, 640, 3]))\n",
    "prediction_dict = detection_model.predict(image, shapes)\n",
    "_ = detection_model.postprocess(prediction_dict, shapes)\n",
    "print('Weights restored!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_learning_phase(True)\n",
    "\n",
    "batch_size = 4\n",
    "learning_rate = 0.01\n",
    "num_batches = 100\n",
    "\n",
    "trainable_variables = detection_model.trainable_variables\n",
    "to_fine_tune = []\n",
    "prefixes_to_train = [\n",
    "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead',\n",
    "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead']\n",
    "for var in trainable_variables:\n",
    "  if any([var.name.startswith(prefix) for prefix in prefixes_to_train]):\n",
    "    to_fine_tune.append(var)\n",
    "\n",
    "def get_model_train_step_function(model, optimizer, vars_to_fine_tune):\n",
    "  \"\"\"Получение tf.function для шага обучения\"\"\"\n",
    "  @tf.function\n",
    "  def train_step_fn(image_tensors,\n",
    "                    groundtruth_boxes_list,\n",
    "                    groundtruth_classes_list):\n",
    "    \n",
    "    shapes = tf.constant(batch_size * [[640, 640, 3]], dtype=tf.int32)\n",
    "    model.provide_groundtruth(\n",
    "        groundtruth_boxes_list=groundtruth_boxes_list,\n",
    "        groundtruth_classes_list=groundtruth_classes_list)\n",
    "    with tf.GradientTape() as tape:\n",
    "      preprocessed_images = tf.concat(\n",
    "          [detection_model.preprocess(image_tensor)[0]\n",
    "           for image_tensor in image_tensors], axis=0)\n",
    "      prediction_dict = model.predict(preprocessed_images, shapes)\n",
    "      losses_dict = model.loss(prediction_dict, shapes)\n",
    "      total_loss = losses_dict['Loss/localization_loss'] + losses_dict['Loss/classification_loss']\n",
    "      gradients = tape.gradient(total_loss, vars_to_fine_tune)\n",
    "      optimizer.apply_gradients(zip(gradients, vars_to_fine_tune))\n",
    "    return total_loss\n",
    "\n",
    "  return train_step_fn\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "train_step_fn = get_model_train_step_function(detection_model, optimizer, to_fine_tune)\n",
    "\n",
    "print('Start fine-tuning!', flush=True)\n",
    "for idx in range(num_batches):\n",
    "  all_keys = list(range(len(train_images_np)))\n",
    "  random.shuffle(all_keys)\n",
    "  example_keys = all_keys[:batch_size]\n",
    "\n",
    "  gt_boxes_list = [gt_box_tensors[key] for key in example_keys]\n",
    "  gt_classes_list = [gt_classes_one_hot_tensors[key] for key in example_keys]\n",
    "  image_tensors = [train_image_tensors[key] for key in example_keys]\n",
    "\n",
    "  total_loss = train_step_fn(image_tensors, gt_boxes_list, gt_classes_list)\n",
    "\n",
    "  if idx % 10 == 0:\n",
    "    print('batch ' + str(idx) + ' of ' + str(num_batches)\n",
    "    + ', loss=' +  str(total_loss.numpy()), flush=True)\n",
    "\n",
    "print('Done fine-tuning!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
