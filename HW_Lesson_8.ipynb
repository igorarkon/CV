{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, ds_info = tfds.load('lfw', \n",
    "                              as_supervised=True, \n",
    "                              with_info=True,  \n",
    "                              split='train') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "for j, (label, image) in enumerate(train_ds.take(24)):\n",
    "    plt.subplot(4, 6, j+1)\n",
    "    plt.title(label.numpy().decode('utf-8')) \n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 100\n",
    "INP_SIZE = 64\n",
    "NUM_EPOCHS = 50\n",
    "HALF_BATCH_SIZE = 16  \n",
    "BATCH_SIZE = HALF_BATCH_SIZE * 2  \n",
    "LEARNING_RATE = 0.0002\n",
    "\n",
    "def preprocessing(img):\n",
    "  img = (tf.cast(img, tf.float32) - 127.5) / 127.5  \n",
    "  return tf.image.resize(img, (INP_SIZE, INP_SIZE))\n",
    "\n",
    "train_ds = train_ds.shuffle(buffer_size=len(train_ds))\n",
    "train_ds = train_ds.map(lambda label, img: (preprocessing(img), label))\n",
    "train_ds = train_ds.repeat(NUM_EPOCHS)\n",
    "train_ds = train_ds.batch(HALF_BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_ds:\n",
    "  print(image.shape)\n",
    "  print(label.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128*16*16, activation='relu'),\n",
    "    tf.keras.layers.Reshape((16, 16, 128)),\n",
    "    tf.keras.layers.UpSampling2D((2, 2)),    \n",
    "    tf.keras.layers.Conv2D(128, (3, 3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.8),\n",
    "    tf.keras.layers.ReLU(),    \n",
    "    tf.keras.layers.UpSampling2D((2, 2)),    \n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.8),\n",
    "    tf.keras.layers.ReLU(),    \n",
    "    tf.keras.layers.Conv2D(3, (3, 3), padding='same', activation='tanh'),\n",
    "])\n",
    "\n",
    "noise = np.random.normal(0, 1, (HALF_BATCH_SIZE, INPUT_DIM)).astype(np.float32)\n",
    "syntetic_images = generator.predict(noise)\n",
    "syntetic_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same'),\n",
    "    tf.keras.layers.LeakyReLU(0.2),\n",
    "    tf.keras.layers.Dropout(0.25),    \n",
    "    tf.keras.layers.Conv2D(64, kernel_size=3, strides=(2, 2), padding='same'),\n",
    "    tf.keras.layers.ZeroPadding2D(padding=((0, 1), (0, 1))),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.8),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv2D(128, kernel_size=3, strides=(2, 2), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.8),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Conv2D(256, kernel_size=3, strides=(1, 1), padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(momentum=0.8),\n",
    "    tf.keras.layers.LeakyReLU(alpha=0.2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "decision = discriminator(syntetic_images)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "sigmoid_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(samples):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    num = samples.shape[0]\n",
    "    for j in range(num):\n",
    "        ax = fig.add_subplot(8, 8, j+1)\n",
    "        new_img = (samples[j, ...] * 127.5) + 127.5\n",
    "        new_img = (tf.cast(new_img, tf.int16))\n",
    "        ax.imshow(new_img)\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (true_images, labels) in enumerate(train_ds):\n",
    "     \n",
    "    # Train Discriminator\n",
    "    \n",
    "    noise = np.random.normal(0, 1, (HALF_BATCH_SIZE, INPUT_DIM)).astype(np.float32)\n",
    "    syntetic_images = generator.predict(noise)\n",
    "    x_combined = np.concatenate((\n",
    "        true_images, \n",
    "        syntetic_images))\n",
    "    y_combined = np.concatenate((\n",
    "        np.ones((HALF_BATCH_SIZE, 1), np.float32), \n",
    "        np.zeros((HALF_BATCH_SIZE, 1), np.float32)))\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = discriminator(x_combined, training=True)\n",
    "        d_loss_value = sigmoid_cross_entropy(y_combined, logits)\n",
    "    grads = tape.gradient(d_loss_value, discriminator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "    \n",
    "    # Train Generator\n",
    "    \n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, INPUT_DIM)).astype(np.float32)\n",
    "    y_mislabled = np.ones((BATCH_SIZE, 1), np.float32)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        syntetic = generator(noise, training=True)\n",
    "        logits = discriminator(syntetic, training=False)\n",
    "        g_loss_value = sigmoid_cross_entropy(y_mislabled, logits)\n",
    "    grads = tape.gradient(g_loss_value, generator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "    \n",
    "    # Check intermediate results\n",
    "    \n",
    "    if step % 500 == 0:\n",
    "        print('[Step %2d] D Loss: %.4f; G Loss: %.4f' % (\n",
    "            step, d_loss_value.numpy(), g_loss_value.numpy()))\n",
    "        noise = np.random.normal(0, 1, (8, INPUT_DIM)).astype(np.float32)\n",
    "        syntetic_images = generator.predict(noise)\n",
    "        plot_results(syntetic_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(0, 1, (32, INPUT_DIM)).astype(np.float32)\n",
    "syntetic_images = generator.predict(noise)\n",
    "plot_results(syntetic_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_1 = np.random.normal(0, 1, (INPUT_DIM)).astype(np.float32)\n",
    "noise_2 = np.random.normal(0, 1, (INPUT_DIM)).astype(np.float32)\n",
    "noise = np.linspace(noise_1, noise_2, 32)\n",
    "syntetic_images = generator.predict(noise)\n",
    "plot_results(syntetic_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
